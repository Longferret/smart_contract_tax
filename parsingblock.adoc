[role="pagenumrestart"]
[[parsing_section]]
= Parsing the blockchain
This section contains my methods and what I learned on how to parse the Ethereum blockchain.

[[methodology]]
== Methodology
There are 2 ways to parse the ethereum blockchain Third parties or having its own node.

My choice to parse the blockchain is to have my own node.
The reason is that a third party can limit the number of queries or totaly block the access.
With my own node, I can dirretly querry the ethereum blockchain.

There is just one problem, it is not possible for me to have an archive node, which contains every transaction since ethereum genesis because it is requires more than 13TB.
I'am going to run a full node which contains the current state of the blockchain only the 128 last blocks and is approximately 1TB.

source: https://www.quicknode.com/guides/infrastructure/node-setup/ethereum-full-node-vs-archive-node

Note: I'am using an other computer (CPU: intel i7-9750H 2.60GHz /RAM: 16GB /SSD: 1TB /running lastest ubuntu version) in pair with a 2TB external SSD.

[[client_choice]]
=== Client Choice
To run a node on the Ethereum blockchain, one needs an execution client and a consensus client.

* The execution client is responsible for all new transactions broadcasted in the network, it executes them in EVM, and holds the latest state and database of all current Ethereum data.
* The consensus client implements the proof-of-stake consensus algorithm.

source: https://ethereum.org/en/developers/docs/nodes-and-clients/

There are different execution and consensus clients.

My choice for the execution client is Go Ethereum (Geth).
I chose it because it is the most popular execution client and is there since the beginning of ethereum.
It is written in Go and fully open-source.
I also thought of using Erigon, but it is only available for an archive node (3TB).

My choice for the consensus client was Lighthouse for the same reasons (is there from the genesis of the beacon chain and is the most popular).
But after more research, I learned that prysm is simpler client to install and run.
But nimbus is lighter (less RAM usage) so I went for it.

[[set_up_node]]
=== Setting up my node
Install the execution client: https://geth.ethereum.org/docs/getting-started

Install the consensus client: https://nimbus.guide/
After a lot of bugs and some time (3 days to sync) my node is synced.

Bug encountered:

* An external SSD was too slow to sync and never reached the current state of the blockchain, I decided to store the chaindata (old data) in the external SSD and the current blockchain data on the computer to solve the problem.
* Geth was using too much RAM which made ubuntu freezing, I fixed it adding the command line --cache 2048 to limit the cache used by geth (default was 4096).
* The USBC cable to my computer was bad and made the chaindata database get corrupted multiple times, I changed the USBC to a simple USB cable to solve the issue.
* The node was still crashing because prysm used 8+ GB of RAM, nimbus only use 2-3 GB of RAM.

[[node_anamysis]]
== Node analysis
An ethereum node can be queried by using the JSON-RPC API.

https://ethereum.org/developers/docs/apis/json-rpc

[[query_third_party]]
=== Query using third party
I began by using an external service while I was waiting to have my own node.
I used Infura to make my first tests to query the blockchain using the JSON-RPC API (over HTTP).

My Idea to gather smarts contracts is to read all transactions when a new block is added and watch for new smart contracts publication.

The https://github.com/Longferret/smart_contract_tax/blob/main/code/gather_contract/first_query.py[script] I created get the last block number, analyze all transaction in it and wait for the next block to analyze it.
I used python for simplicity.

We can spot a contract deployment by looking at the "to" attribute of a transaction which contains no address and then we can use the transaction receipt to get the address of the contract and its bytecode.

Notes:

* With an external node provider like Infura, we can't read blocks in real time, the provider limits the amount of query per second so the block are added faster than we can read them.
* We only retreive the bytecodes and the contract addresses.
* By only looking at the "to" field of a transaction, we only get contract created by ordinary addresses (users).


[[query_blockchain]]
=== Query using my own node

https://github.com/Longferret/smart_contract_tax/blob/main/code/gather_contract/gather_contract.py[Script to gather contracts]

I used the same strategy as above but with my own node and I added an analysis of the traces.

What it does:

* analysis of "to" field of the transactions to spot contract created by ordinary addresses
* analysis of the traces of the transactions to spot contract created by internal calls
* group smart contracts by their day of creation
* save bytecode, contract address and creation type

More explanation:

An internal call is not directly visible in the transactions, it happens when a smart contract deploy or call another smart contract.
The only way to spot them is to watch the bytecode executed at each transaction, this information is in the traces of the transaction.

I tried to get the trace for each transaction in a block, but this method is too slow and can't keep up with the new block arriving. It is due to the execution client sending directy each transaction trace 1 by 1 to the python script.

The most efficient way to get the traces of transactions is to call https://geth.ethereum.org/docs/interacting-with-geth/rpc/ns-debug[debug_standardTraceBlockToFile].
It stores all the traces of a given block in the temp folder.
The script then analyse the current block searching for the opcode "CREATE" or "CREATE2".

CREATE: creation of a smart contract with non deterministic contract address

CREATE2: creation of a smart contract with deterministic contract address

https://ethervm.io/

The address of the contract is on top of the stack at the next intruction (can be tracked thanks to the program counter in the traces).

https://github.com/Longferret/smart_contract_tax/blob/main/code/gather_contract/source_search.py[Script to retreive Source Code and analyze with slither]

It is used to get the source code of all smart contract if they are available by using the Etherscan API.
It also run an security flaw analysis (on solidity code) using slither, only the medium and high impact flaws are saved. (in the file slither.txt with JSON format)

Notes:

* The first script gather contract in real time.
* The second has to be executed manually and search all source code of contracts for a given day.
* A possible next step is the analysis of the gathered contracts using other analysis tools and analyzing result of slither.
* (15/02/2024) Currently gathered contracts 1500 (source code available: 350, by internal 1273, by ordinary 207)


